{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "##part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = len(df)\n",
    "#print(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1 for i in range(sh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(1, 'b', l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = df.iloc[:,1:-1].values\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "yd = df.iloc[:,-1].values\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(xd)\n",
    "y = np.array(yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = x.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx = np.matmul(xt,x)\n",
    "inv_xtx = np.linalg.inv(xtx)\n",
    "#print(inv_xtx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.matmul(inv_xtx,xt)\n",
    "#print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.matmul(a,y)\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"weightfile_a.txt\",\"w\")\n",
    "for i in w:\n",
    "    file.write(str(i))\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"data/test.csv\")\n",
    "sh2 = len(df2)\n",
    "l2 = [1 for i in range(sh2)]\n",
    "df2.insert(1,'b',l2)\n",
    "xd2 = df2.iloc[:,1:]\n",
    "x2 = np.array(xd2)\n",
    "y = np.matmul(x2,w)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"outputfile_a.txt\",\"w\")\n",
    "for i in y:\n",
    "    file.write(str(i))\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "##part a ended here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "rows = len(df0.axes[0])\n",
    "width = len(df0.axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1 for i in range(rows)]\n",
    "df0.insert(1,'b',l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(x,w,y):\n",
    "    y_pred = np.matmul(x,w)\n",
    "    #pred_error = np.sum(np.square(y_pred - y))/np.sum(np.square(y))\n",
    "    k = np.linalg.norm(y_pred-y)/np.linalg.norm(y)\n",
    "    return k;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWeight(x,y,lamb):\n",
    "    xt = x.transpose()\n",
    "    xtx = np.matmul(xt,x)\n",
    "    I = np.identity(len(xtx))\n",
    "    lamb_I = np.dot(lamb,I)\n",
    "    inv = np.linalg.inv(xtx+lamb_I)\n",
    "    a = np.matmul(inv,xt)\n",
    "    w = np.matmul(a,y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimalWeightError(rows,lamb,df0):\n",
    "    #print(\"-----------\")\n",
    "    i = rows//10\n",
    "    errors = list()\n",
    "    #errors = np.array(errors)\n",
    "    for j in range(10):\n",
    "        start = i*j\n",
    "        end = i*(j+1)\n",
    "        \n",
    "        #test x and y\n",
    "        x_test = df0.iloc[start:end+1,1:-1].values\n",
    "        y_test = df0.iloc[start:end+1,-1].values\n",
    "        \n",
    "        \n",
    "        #train x\n",
    "        x_train1 = df0.iloc[:start,1:-1]\n",
    "        x_train2 = df0.iloc[end+1:,1:-1]\n",
    "        frames = [x_train1,x_train2]\n",
    "        x_train = pd.concat(frames).values\n",
    "        \n",
    "        #train y\n",
    "        y_train1 = df0.iloc[:start,-1]\n",
    "        y_train2 = df0.iloc[end+1:,-1]\n",
    "        frames = [y_train1,y_train2]\n",
    "        y_train = pd.concat(frames).values\n",
    "        \n",
    "        \n",
    "        #finding weight\n",
    "        y = np.array(y_train)\n",
    "        x = np.array(x_train)\n",
    "        w = findWeight(x,y,lamb)\n",
    "        \n",
    "        #print(w)\n",
    "        \n",
    "        #finding error\n",
    "        x_test = np.array(x_test)\n",
    "        y_test = np.array(y_test)\n",
    "        error = err(x_test,w,y_test)\n",
    "        \n",
    "        #print(x)\n",
    "        errors.append(error)\n",
    "        #np.append(errors, error)\n",
    "        \n",
    "        \n",
    "    \n",
    "    k = np.sum(np.square(errors))\n",
    "    k = math.sqrt(k)\n",
    "    #k = np.sum(errors)/len(errors)\n",
    "    #print(errors)\n",
    "            \n",
    "    #print(err_min)\n",
    "    #print(w)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb_list = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 15, 20, 25, 30, 100, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = float('inf')\n",
    "lamb_min = 0\n",
    "for lamb in lamb_list:\n",
    "    k = getOptimalWeightError(rows,lamb,df0)\n",
    "    error = k\n",
    "    if error < t:\n",
    "        t = error\n",
    "        lamb_min = lamb\n",
    "        \n",
    "x = df0.iloc[:,1:-1].values\n",
    "y_train = df0.iloc[:,-1].values\n",
    "w_min = findWeight(x,y_train,lamb_min)\n",
    "#print(\"---\")\n",
    "#print(t)\n",
    "#print(lamb_min)\n",
    "#print(w_min)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"weightfile_b.txt\",\"w\")\n",
    "for i in w:\n",
    "    file.write(str(i))\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"data/test.csv\")\n",
    "sh2 = len(df2)\n",
    "l2 = [1 for i in range(sh2)]\n",
    "df2.insert(1,'b',l2)\n",
    "xd2 = df2.iloc[:,1:]\n",
    "x2 = np.array(xd2)\n",
    "y_b = np.matmul(x2,w)\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"outputfile_b.txt\",\"w\")\n",
    "for i in y_b:\n",
    "    file.write(str(i))\n",
    "    file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part b ended here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part C started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2Score(w,x,y):\n",
    "    y_pred = np.matmul(x,w)\n",
    "    u = np.sum(np.square(y_pred-y))\n",
    "    v = np.sum(np.square(y - np.mean(y)))\n",
    "    err = 1-u/v\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "rows = len(df0.axes[0])\n",
    "width = len(df0.axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1 for i in range(rows)]\n",
    "df0.insert(1,'b',l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = df0.iloc[:,1:-1].values\n",
    "yd = df0.iloc[:,-1].values\n",
    "x = np.array(xd)\n",
    "y = np.array(yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = poly.fit_transform(x)\n",
    "#print(x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clms = df0.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LassoLars(alpha = 0.0001,max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\Anaconda3\\envs\\col341_test\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.570e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\aksha\\Anaconda3\\envs\\col341_test\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.473e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\aksha\\Anaconda3\\envs\\col341_test\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.405e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\aksha\\Anaconda3\\envs\\col341_test\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.387e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\aksha\\Anaconda3\\envs\\col341_test\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:642: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=1.345e+00, previous alpha=1.329e+00, with an active set of 18 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLars(alpha=0.0001, max_iter=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/train_large.csv\")\n",
    "\n",
    "rows = len(df1.axes[0])\n",
    "width = len(df1.axes[1])\n",
    "\n",
    "l = [1 for i in range(rows)]\n",
    "df1.insert(1,'b',l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7060271703084401"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd_test = df1.iloc[:50000,1:-1].values\n",
    "yd_test = df1.iloc[:50000,-1].values\n",
    "x_test = np.array(xd_test)\n",
    "y_test = np.array(yd_test)\n",
    "\n",
    "x_train_new = poly.fit_transform(x_test)\n",
    "\n",
    "reg.score(x_train_new,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "#rows_2 = len(df1.axes[0])\n",
    "#width_2 = len(df1.axes[1])\n",
    "#l_2 = [1 for i in range(rows_2)]\n",
    "#df1.insert(1,'b',l_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xd_test = df1.iloc[:,1:-1].values\n",
    "#yd_test = df1.iloc[:,-1].values\n",
    "#x_test = np.array(xd_test)\n",
    "#y_test = np.array(yd_test)\n",
    "#r2score = r2Score(w,x_test,y_test)\n",
    "#print(r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.loc[:,\"b\"].values\n",
    "Risk = df.loc[:,\"APR Risk of Mortality\"].values\n",
    "Hospital_country = df.loc[:,\"Hospital County\"].values\n",
    "Ethnicity = df.loc[:,\"Ethnicity\"].values\n",
    "Facility_id = df.loc[:,\"Facility Id\"].values\n",
    "Zip = df.loc[:,\"Zip Code - 3 digits\"].values\n",
    "MDC_Description = df.loc[:,\"APR MDC Description\"].values\n",
    "Patient_Disposition = df.loc[:,\"Patient Disposition\"].values\n",
    "CCS_Procedure_desciption = df.loc[:,\"CCS Procedure Description\"].values\n",
    "Illness_code = df.loc[:,\"APR Severity of Illness Code\"].values\n",
    "Illness_desc = df.loc[:,\"APR Severity of Illness Description\"].values\n",
    "MDC_Code = df.loc[:,\"APR MDC Code\"].values\n",
    "Birth_w = df.loc[:,\"Birth Weight\"].values\n",
    "Name = df.loc[:,\"Facility Name\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = len(b)\n",
    "f1 = np.add(b,Risk)\n",
    "f2 = np.add(Hospital_country,Ethnicity)\n",
    "f3 = np.add(Hospital_country,Risk)\n",
    "f4 = np.add(Facility_id,Ethnicity)\n",
    "f5 = np.add(Zip,Risk)\n",
    "f6 = np.add(Ethnicity,MDC_Description)\n",
    "f7 = np.add(Ethnicity,Risk)\n",
    "f8 = np.add(Patient_Disposition,CCS_Procedure_desciption)\n",
    "f9 = np.add(MDC_Description,Risk)\n",
    "f10= np.square(Ethnicity)\n",
    "f11 = np.square(Risk)\n",
    "f12 = np.array(Name)\n",
    "f13 = np.add(Ethnicity,Patient_Disposition)\n",
    "f14 = np.add(Ethnicity,CCS_Procedure_desciption)\n",
    "f15 = np.add(CCS_Procedure_desciption,Illness_code)\n",
    "f16 = np.add(CCS_Procedure_desciption,Illness_desc)\n",
    "f17 = np.add(MDC_Code,Birth_w)\n",
    "\n",
    "x_featured = np.column_stack((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17))\n",
    "#print(x_featured.shape)\n",
    "#print(f1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateWeight(x,y):\n",
    "    xt = x.transpose()\n",
    "    xtx = np.matmul(xt,x)\n",
    "    inv_xtx = np.linalg.inv(xtx)\n",
    "    a = np.matmul(inv_xtx,xt)\n",
    "    w = np.matmul(a,y)\n",
    "    return w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_featured = calculateWeight(x_featured,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(w_featured))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w_featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"data/test.csv\")\n",
    "##sh2 = len(df)\n",
    "#l2 = [1 for i in range(sh2)]\n",
    "#df.insert(1,'b',l2)\n",
    "#xd2 = df2.iloc[:,1:]\n",
    "#x2 = np.array(xd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = df.loc[:,\"b\"].values\n",
    "#Risk = df.loc[:,\"APR Risk of Mortality\"].values\n",
    "#Hospital_country = df.loc[:,\"Hospital County\"].values\n",
    "#Ethnicity = df.loc[:,\"Ethnicity\"].values\n",
    "#Facility_id = df.loc[:,\"Facility Id\"].values\n",
    "#Zip = df.loc[:,\"Zip Code - 3 digits\"].values\n",
    "#MDC_Description = df.loc[:,\"APR MDC Description\"].values\n",
    "#Patient_Disposition = df.loc[:,\"Patient Disposition\"].values\n",
    "#CCS_Procedure_desciption = df.loc[:,\"CCS Procedure Description\"].values\n",
    "#Illness_code = df.loc[:,\"APR Severity of Illness Code\"].values\n",
    "#Illness_desc = df.loc[:,\"APR Severity of Illness Description\"].values\n",
    "#MDC_Code = df.loc[:,\"APR MDC Code\"].values\n",
    "#Birth_w = df.loc[:,\"Birth Weight\"].values\n",
    "#Name = df.loc[:,\"Facility Name\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = len(b)\n",
    "#f1 = np.add(b,Risk)\n",
    "#f2 = np.add(Hospital_country,Ethnicity)\n",
    "#f3 = np.add(Hospital_country,Risk)\n",
    "#f4 = np.add(Facility_id,Ethnicity)\n",
    "#f5 = np.add(Zip,Risk)\n",
    "#f6 = np.add(Ethnicity,MDC_Description)\n",
    "#f7 = np.add(Ethnicity,Risk)\n",
    "#f8 = np.add(Patient_Disposition,CCS_Procedure_desciption)\n",
    "#f9 = np.add(MDC_Description,Risk)\n",
    "#f10= np.square(Ethnicity)\n",
    "#f11 = np.square(Risk)\n",
    "#f12 = np.array(Name)\n",
    "#f13 = np.add(Ethnicity,Patient_Disposition)\n",
    "#f14 = np.add(Ethnicity,CCS_Procedure_desciption)\n",
    "#f15 = np.add(CCS_Procedure_desciption,Illness_code)\n",
    "#f16 = np.add(CCS_Procedure_desciption,Illness_desc)\n",
    "#f17 = np.add(MDC_Code,Birth_w)\n",
    "\n",
    "#x_featured = np.column_stack((f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17))\n",
    "#print(x_featured.shape)\n",
    "#print(f1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_small = np.matmul(x_featured,w_featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open(\"outputfile_c.txt\",\"w\")\n",
    "#for i in y_test_small:\n",
    "#    file.write(str(i))\n",
    "#    file.write(\"\\n\")\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here I am testing on the train_large dataset and calculating the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv(\"data/train_large.csv\")\n",
    "\n",
    "#rows_2 = len(df1.axes[0])\n",
    "#width_2 = len(df1.axes[1])\n",
    "#l_2 = [1 for i in range(rows_2)]\n",
    "#df1.insert(1,'b',l_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xd_test = df1.iloc[:50000,1:-1].values\n",
    "#yd_test = df1.iloc[:50000,-1].values\n",
    "#x_test = np.array(xd_test)\n",
    "#y_test = np.array(yd_test)\n",
    "#r2score = r2Score(w,x_test,y_test)\n",
    "#print(r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part C is closed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:col341_test]",
   "language": "python",
   "name": "conda-env-col341_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
